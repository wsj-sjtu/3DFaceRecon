
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>

<link rel="stylesheet" type="text/css" href="style.css" />
  

<!-- End : Google Analytics Code -->
<script type="text/javascript" src="../js/hidebib.js"></script>
<!-- <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'> -->
<!-- <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300,300italic,400italic,600,600italic,700,700italic,800,800italic' rel='stylesheet' type='text/css'> -->
<link href='https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro' rel='stylesheet' type='text/css'>
  
<head>
    <title>Towards Photo-Realistic 3D Face Reconstruction from a Single Image</title>
    <meta property="og:description" content="GANHead: Towards Generative Animatable Neural Head Avatars"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6HHDEXF452"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-6HHDEXF452');
</script>

</head>


 <body>
<div class="container">
    <div class="paper-title">
      <h1>Towards Photo-Realistic 3D Face Reconstruction from a Single Image</h1>
    </div>

    
    <div id="authors">
      
        <table class="author-row" align=center width="50%">
            <tr>
            <td colspan="1">
                Sijing Wu
            </td>
            <td colspan="1">
                Huiyu Duan
            </td>
            <td colspan="1">
                <a href="https://daodaofr.github.io/">Yichao Yan</a>
            </td>
            <td colspan="1">
                <a href="https://scholar.google.com/citations?user=E6zbSYgAAAAJ&hl=en&oi=ao">Guangtao Zhai</a>
            </td>
            </tr>
        </table>

        <div class="affil-row" align=center>
            <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a>
        </div>

    </div>
                                            

    <section id="abstract"/>
        <h2>Abstract</h2>
        <hr/>

        <p>Reconstructing the 3D face from a single image is an ill-posed problem, so that 3D Morphable Models (3DMMs) are widely used to reduce ambiguity. 
           However, 3D faces reconstructed by directly estimating 3DMM parameters are far from photo-realistic due to the limited representation power of 3DMMs. 
           In this paper, we propose a novel framework to break through the limitations of 3DMMs without additional 3D data. 
           The main idea is that well-aligned coarse geometry along with high-fidelity texture is the most economical way to achieve photo-realistic 3D face reconstruction, and the geometry and texture can be optimized in a synergetic manner (i.e., accurate geometry leads to better texture, while high-fidelity texture promotes the refinement of the geometry). 
           Specifically, the texture is extracted from the input image and the invisible part is completed by an inpainting network trained via a novel unsupervised manner. Different from existing UV completion methods, we treat it as an unsupervised domain adaptation problem for image inpainting, since we have ground truth data (i.e., complete UV texture) in the 3DMM domain (i.e., source domain) but not in the real texture domain (i.e., target domain). To this end, we train an unpaired image-to-image translation network to translate complete 3DMM texture to the real domain which is then used to train the UV texture inpainting network. 
           As for the geometry, we propose a graph convolutional network (GCN) based mesh deformation module to perform free-form deformation to the coarse geometry recovered by 3DMM to break through the limited representation power of 3DMM. The deformed geometry is then used to extract UV texture from the input image which is then completed by the pre-trained inpainting network. The refined geometry alone with complete UV texture is then rerendered to the image for self-supervised training of the deformation module. 
           Extensive experiments demonstrate the superiority of our method over previous work. Furthermore, our method can be used for monocular 3D caricature face reconstruction based on normal face 3DMM (without the need for 3D caricature face data).
        </p>
    </section>

    
    <section id="Demo Video">
        <h2>Demo Video</h2>
        <hr/>
        <figure style="width: 100%;">
            <video class="centered" width="100%" controls muted loop autoplay>
                <source src="assets/demo_new.mp4" type="video/mp4">
            </video>
            <p class="caption">The demo video shows the latent code sampling and head avatar generation results, followed by the animation results controlled by FLAME parameters.
            </p>
        </figure>
        <hr/>
    </section>

    <section id="Applications">
        <h2>Application</h2>
        <hr/>
        <h3>Face Reenactment</h3>
        <figure style="width: 100%;">
            <video class="centered" width="100%" controls muted loop autoplay>
                <source src="assets/reenactment.mp4" type="video/mp4">
            </video>
            <p class="caption"> We estimate the FLAME parameters of the sourse video, and use the estimated pose and expression parameters to animate the generated head avatars. 
                                The generated avatars can fully reproduce FLAME's poses and expressions.
            </p>
        </figure>
        <br/>
        <hr/>
      
        <h3>Raw Scan Fitting</h3>
        <figure style="width: 80%;">
            <a href="assets/fitting.png">
                <img width="100%" src="assets/fitting.png">
            </a>
        </figure>
        <figure style="width: 100%;">
            <p class="caption">
                Our model can also be fitted to raw scans to produce personal animatable head avatars.
            </p>
        </figure>
    </section>

    <section id="Other Results">
        <h2>Other Results</h2>
        <hr/>
        <table align=center width="100%">
            <tr>
            <td colspan="4">
                <h3>Sample Latent Codes</h3>
            </td>
            <td colspan="5">
                <h3>Raw Scan Fitting</h3>
            </td>
            </tr>
          
            <tr>
            <td colspan="2">
                <center>
                <video width=150px controls muted loop autoplay>
                    <source src="assets/shape_code.mp4" type="video/mp4">
                </video>
            </center>
            </td>
            <td colspan="2">
                <center>
                <video width=150px controls muted loop autoplay>
                    <source src="assets/detail_code.mp4" type="video/mp4">
                </video>
                </center>
            </td>
            <td colspan="5">
                <center>
                <a href="assets/multiface_fitting.png">
                    <img width=640px src="assets/multiface_fitting.png">
                </a>
                </center>
            </td>
            </tr>
        </table>
        <p class="caption"> We also train our model on a subset of Multiface datase. Since Multiface datase has less detail and noise in the hair region, 
                            our model can learn more details of th facial region and achieve better fitting results.
        </p>
        <hr/>
    </section>


</div>
</body>
</html>
